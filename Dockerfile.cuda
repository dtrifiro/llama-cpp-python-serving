FROM registry.access.redhat.com/ubi9/ubi:latest as cuda-base
ARG CUDA_VERSION=12-3

ENV CUDA_VERSION=${CUDA_VERSION}

RUN dnf config-manager --add-repo https://developer.download.nvidia.com/compute/cuda/repos/rhel9/x86_64/cuda-rhel9.repo && \
    dnf install -y  \
        cuda-cudart-${CUDA_VERSION} \
        cuda-compat-${CUDA_VERSION} \
        libcublas-${CUDA_VERSION} \
    && \
    echo "/usr/local/nvidia/lib" >> /etc/ld.so.conf.d/nvidia.conf && \
    echo "/usr/local/nvidia/lib64" >> /etc/ld.so.conf.d/nvidia.conf && \
    dnf clean all

ENV CUDA_HOME="/usr/local/cuda"
ENV PATH="/usr/local/nvidia/bin:${CUDA_HOME}/bin:${PATH}"
ENV LD_LIBRARY_PATH="/usr/local/nvidia/lib:/usr/local/nvidia/lib64:$CUDA_HOME/lib64:$CUDA_HOME/extras/CUPTI/lib64:${LD_LIBRARY_PATH}"


FROM cuda-base as builder
ARG CUDA_VERSION
ENV CUDA_VERSION=${CUDA_VERSION}

RUN dnf config-manager --add-repo https://developer.download.nvidia.com/compute/cuda/repos/rhel9/x86_64/cuda-rhel9.repo && \
    dnf -y install \
        git gcc-toolset-12-gcc-c++ gcc-toolset-12 cmake python3.11-pip \
        cuda-nvcc-${CUDA_VERSION} \
        libcublas-devel-${CUDA_VERSION} \
        cuda-cudart-devel-${CUDA_VERSION} \
        cuda-driver-devel-${CUDA_VERSION} \
    && \
    dnf clean all && \
    pip3.11 install --no-cache-dir --upgrade pip wheel

ENV POETRY_VIRTUALENVS_IN_PROJECT=1

WORKDIR /llama-cpp-python
COPY pyproject.toml .
COPY poetry.lock .

ENV CMAKE_ARGS="-DLLAMA_CUBLAS=on"
RUN pip3.11 install poetry && \
    scl enable gcc-toolset-12 -- poetry install


FROM cuda-base as deploy

RUN dnf -y install \
        shadow-utils python3.11 && \
    dnf clean all

WORKDIR /llama-cpp-python

COPY --from=builder /llama-cpp-python/.venv /llama-cpp-python/.venv

ENV VIRTUAL_ENV=/llama-cpp-python/.venv
ENV PATH="$VIRTUAL_ENV/bin:$PATH"

RUN groupadd --system llama --gid 1001 && \
    adduser --system --uid 1001 --gid 0 --groups llama \
    --create-home --home-dir /llama-cpp-python --shell /sbin/nologin \
    --comment "Llama user" llama

USER llama

# TODO: configuration?
ENTRYPOINT ["python", "-m", "llama_cpp.server"]
