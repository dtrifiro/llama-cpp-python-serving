apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: llama-cpp-python-claim
spec:
  accessModes:
    - ReadWriteOnce
  volumeMode: Filesystem
  resources:
    requests:
      storage: 100Gi
---
apiVersion: v1
# TODO: could use a Job instead of a Pod
kind: Pod
metadata:
  name: setup-model
spec:
  volumes:
    - name: model-volume
      persistentVolumeClaim:
        claimName: llama-cpp-python-claim
  restartPolicy: Never
  containers:
    - name: download-model
      image: busybox
      command: [
          "wget",
          "-P",
          "/mnt/models/",
          "--continue", # can help if the download fails and the pod needs to be restarted
          "--output-document",
          "model.gguf",
          "<dummy>", # replace this or use kustomize
        ]
      volumeMounts:
        - mountPath: "/mnt/models/"
          name: model-volume
